{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e5d1817-fe87-4777-b5e7-f91c178af237",
   "metadata": {},
   "source": [
    "# Previous Lesson Overview - Day 8 Pandas_Math\n",
    "\n",
    "Instructor/Notebook creator: Maria D Hernandez Limon\n",
    "\n",
    "**AI assistance:** Maria used ChatGPT on *Aug2025* to help with commenting code, brainstorm and design of homework problems.\n",
    "I reviewed/edited the code, added comments, and validated results with tests/spot checks.\n",
    "\n",
    "In the previous lesson you learned about dataframes: \n",
    "\n",
    "1. Introduction to math and stats with dataframes\n",
    "2. Introduction to groupby and pivot tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501d589f",
   "metadata": {},
   "source": [
    "# Day 09: Seaborn Essentials + SciPy + Maps + Simple Animation \n",
    "\n",
    "**Why this day?**  \n",
    "We level up plots with **Seaborn** and connect your work to **space** (Cartopy/GeoPandas) and **time** (animation).  \n",
    "And add some **stats** to confirm patterns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b845ff",
   "metadata": {},
   "source": [
    "Learning goals (ties to Days 1–8)\n",
    "- Tidy data → quick plots (`lineplot`, `histplot`/`kdeplot`, `barplot`, faceting).\n",
    "- Reuse patterns via **plotting functions** (`ax=` in, Axes out).\n",
    "- Short **Cartopy** map examples (projection + `transform=`).\n",
    "- Small **GIF** using `FuncAnimation` \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401e4e46",
   "metadata": {},
   "source": [
    "# 0. Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771e3d3d-ad34-460a-90e3-c53b93110555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import ticker\n",
    "\n",
    "#seaborn - more advanced plotting options but always import matplotlib too as some seaborn utility comes from matplot\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c83d14-bf2d-4bc9-82ea-14855ce2b3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the specific directory where the data we want to use is stored\n",
    "datadirectory = '../data/'\n",
    "\n",
    "#this is the directory where we want to store the data we finish analyzing\n",
    "data_out_directory='../output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99c2e62-0737-4fef-8d17-97d2ebf8c749",
   "metadata": {},
   "source": [
    "## data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce83f9e5-ad28-4a30-b388-3f823adaa453",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../data/Temp_data_2010-2020.csv\")\n",
    "\n",
    "# 1) Ensure we have a proper Date \n",
    "df['Date'] = pd.to_datetime(df['date'])\n",
    "# Create Day-of-Year\n",
    "df['DoY'] = df['Date'].dt.dayofyear\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc6cd8a",
   "metadata": {},
   "source": [
    "# 1. [Seaborn](https://seaborn.pydata.org/)\n",
    "\n",
    "You can look at the seaborn **[gallery](https://seaborn.pydata.org/examples/index.html)** and look at all the plotting options it offers.\n",
    "\n",
    "we import as:\n",
    "\n",
    "`import seaborn as sns` and after we load matplot.\n",
    "\n",
    "Seaborn has both axes-level plotting functions and figure-level plotting functions.\n",
    "\n",
    "If a seaborn plot has the following text in the description **'This is an Axes-level function'** then you need to map it on to a figure level object that we can make with matplotlib. If it says **'Figure-level interface for drawing relational plots onto a FacetGrid'** then you don't need to use map on to some figure level object because it already is one.\n",
    "\n",
    "- **Tidy** (long) data works best (one row = one observation).  \n",
    "- **Axes-level** funcs (`sns.lineplot`, `sns.barplot`, `sns.histplot`): pass `ax=`, great for subplots.  \n",
    "- **Figure-level** funcs (`sns.relplot`, `sns.displot`, `sns.catplot`): built-in faceting (`row=`, `col=`), return `FacetGrid`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef58004",
   "metadata": {},
   "source": [
    "## 1.1 Choosing a plot (quick guide)\n",
    "| Goal | Data shape | First pick |\n",
    "|---|---|---|\n",
    "| Trend over time | long, Date/Value/Group | `sns.lineplot` |\n",
    "| Compare group means + variability | long | `sns.barplot(estimator=np.mean, errorbar=\"sd\")` |\n",
    "| Distribution | long numeric | `sns.histplot` (+ `kdeplot`) |\n",
    "| Many panels | long + category facet | `sns.relplot(..., col=..., row=...)` |\n",
    "| Relationships (a few vars) | long or wide | `sns.pairplot(..., corner=True)` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e708117-8d08-427e-8b54-e265cb8ebd40",
   "metadata": {},
   "source": [
    "## [SEABORN GALLERY](http://seaborn.pydata.org/examples/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500cd49b-0daf-4618-8988-5d35ea5cb23e",
   "metadata": {},
   "source": [
    "## 1.2 Axes-level vs Figure-level in Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850dd8bc-aa8f-4618-8dc5-ef97f8943580",
   "metadata": {},
   "source": [
    "### A) **Axes-level**: you bring the figure/axes (use ax=)\n",
    "\n",
    "Rule: Functions like sns.lineplot, sns.barplot, sns.histplot, sns.scatterplot, etc. are Axes-level.\n",
    "They return a matplotlib.axes.Axes and accept ax=, so you “map” them onto the figure you create with Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab9afbe-8adb-4c2b-b62b-adcf18721526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset and adjust data\n",
    "year = 2016\n",
    "sub = df.loc[df[\"Year\"] == year].copy()\n",
    "sub = sub.sort_values([\"Lake\",\"Date\"])\n",
    "\n",
    "# ---- 1) YOU create the Matplotlib figure & axes grid (because we'll use Axes-level seaborn functions) ----\n",
    "# 2 rows × 2 cols of subplots; share x/y axes so scales match across panels.\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 6), sharex=True, sharey=True)\n",
    "# axs is a 2×2 array; ravel() flattens it to a 1D list so we can loop easily.\n",
    "axs = axs.ravel()\n",
    "#print(axs)\n",
    "lakes = ['MI','SU','ER','ON']\n",
    "\n",
    "# ---- 2) For Axes-level seaborn functions, you must pass ax= to tell them where to draw ----\n",
    "# these are in axs \n",
    "for ax, lake in zip(axs, lakes):\n",
    "    # Take just this lake’s rows\n",
    "    d = sub.loc[sub[\"Lake\"] == lake]\n",
    "    # Add a 7-day rolling mean of Temp_F.\n",
    "    # rolling(7) looks back up to 7 days; min_periods=3 lets the first few points appear\n",
    "    # instead of being NaN until 7 days are available.\n",
    "    d = d.assign(Roll7=d[\"Temp_F\"].rolling(7, min_periods=3).mean())\n",
    "    #print(d)\n",
    "    # Draw the line on THIS subplot (Axes) using the Axes-level API.\n",
    "    # Because this is Axes-level, we *must* pass ax=ax.\n",
    "    sns.lineplot(data=d, x=\"Date\", y=\"Roll7\", ax=ax)   # <-- Axes-level, mapped onto ax\n",
    "   # Panel title so we know which lake we are looking at\n",
    "    ax.set_title(lake)\n",
    "    # add a horizontal reference line in every facet\n",
    "    ax.axhline(32, lw=1, ls=\"--\", alpha=0.6, color=\"red\")\n",
    "    \n",
    "# A single title for the whole figure (all four panels)\n",
    "fig.suptitle(f\"7-day mean Temp (°F) by Lake — {year}\", y=1.02)\n",
    "\n",
    "#to make fig pretty\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4505d783-52f4-4de1-a0e1-b7f2fe069b38",
   "metadata": {},
   "source": [
    "### B) **Figure-level**: Seaborn creates the figure/grid (no ax=)\n",
    "\n",
    "Rule: Functions like sns.relplot, sns.displot, sns.catplot are Figure-level.\n",
    "They return a FacetGrid, manage the figure and the subplots for you, and support row=, col=, hue=, height=, aspect=.\n",
    "You don’t pass ax= to these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3158fc5-6074-4dc0-9e6f-e398d679566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same data slice and rolling temp calculation as above\n",
    "year = 2016\n",
    "sub = df.loc[(df[\"Year\"] == year) & (df[\"Lake\"].isin(lakes)),].copy()\n",
    "sub = sub.sort_values([\"Lake\",\"Date\"])\n",
    "sub[\"Roll7\"] = sub.groupby(\"Lake\")[\"Temp_F\"].transform(lambda s: s.rolling(7, min_periods=3).mean())\n",
    "\n",
    "# ---- 1) Figure-level call: Seaborn creates the Figure + FacetGrid for you ----\n",
    "# relplot is a *figure-level* function, so we DO NOT pass ax=.\n",
    "# It builds a grid with one small panel per lake (col=\"Lake\"), wrapped into 2 columns.\n",
    "g = sns.relplot(\n",
    "    data=sub, x=\"Date\", y=\"Roll7\",\n",
    "    col=\"Lake\", col_wrap=2, kind=\"line\",\n",
    "    height=3, aspect=1.4,\n",
    "    facet_kws={\"sharey\": True}\n",
    ")\n",
    "\n",
    "# 2) You customize via FacetGrid methods or by looping its axes\n",
    "g.set_axis_labels(\"Date\", \"7-day mean Temp (°F)\").set_titles(\"{col_name}\")\n",
    "\n",
    "# Example: add a horizontal reference line in every facet\n",
    "for ax in g.axes.flatten():\n",
    "    ax.axhline(32, lw=1, ls=\"--\", alpha=0.6, color=\"red\")\n",
    "\n",
    "# Saving: use g.fig (the underlying Matplotlib Figure)\n",
    "g.fig.suptitle(f\"7-day mean Temp (°F) by Lake — {year}\", y=1.02)\n",
    "g.fig.tight_layout()\n",
    "g.fig.savefig(\"../output/facet_relplot.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb544090-70e8-4a78-b7af-84f4c1bcbc4d",
   "metadata": {},
   "source": [
    "| Type             | Examples                                                                  | Returns     | Layout control                                                             | Pass `ax=`? | Best for                                                             |\n",
    "| ---------------- | ------------------------------------------------------------------------- | ----------- | -------------------------------------------------------------------------- | ----------- | -------------------------------------------------------------------- |\n",
    "| **Axes-level**   | `lineplot`, `barplot`, `histplot`, `scatterplot`, `boxplot`, `violinplot` | `Axes`      | **You** define with `plt.subplots()`                                       | **Yes**     | Custom figures, mixing plot types, matching other Matplotlib artists |\n",
    "| **Figure-level** | `relplot`, `displot`, `catplot`                                           | `FacetGrid` | **Seaborn** arranges via `row=`, `col=`, `col_wrap=`, `height=`, `aspect=` | **No**      | Fast faceting, consistent styling and scaling                        |\n",
    "\n",
    "                                                                                                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a74f2fd",
   "metadata": {},
   "source": [
    "## 1.3 Seaborn essentials\n",
    "### 1.31 Line — monthly climatology (mean ± 1 SD) by Lake\n",
    "**What:** Seasonal pattern, per lake.  \n",
    "**Why:** Clean comparison across groups.  \n",
    "**How:** `groupby → agg → sns.lineplot`, fill a band for ±SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ff9d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "df=pd.read_csv(\"../data/Temp_data_2010-2020.csv\")\n",
    "\n",
    "#use groupby to find the mean per month and lake \n",
    "clim = (df.groupby(['Lake','Month'], as_index=False)\n",
    "          .agg(mean_T=('Temp_F','mean'), sd_T=('Temp_F','std')))\n",
    "\n",
    "#initiaize plot \n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "\n",
    "#call searborn line plot \n",
    "sns.lineplot(data=clim, x='Month', y='mean_T', hue='Lake', ax=ax, errorbar=None)\n",
    "\n",
    "#add fill between with a for loop\n",
    "for lake, sub in clim.groupby('Lake'):\n",
    "    ax.fill_between(sub['Month'], sub['mean_T']-sub['sd_T'], sub['mean_T']+sub['sd_T'], alpha=0.15)\n",
    "\n",
    "ax.set(xlabel='Month', ylabel='Temperature (°F)', title='Monthly climatology (mean ± 1 SD)')\n",
    "ax.set_xticks(range(1,13))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1b8060-ffac-4702-b926-6b64349c800a",
   "metadata": {},
   "source": [
    "### Check-in [1]\n",
    "- Change the markers to triangles and add a grid.\n",
    "- figure out how to add a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3360e027-925e-4d49-a6a6-999e6bd523b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data selection \n",
    "subset = df[df[\"Lake\"].isin([\"SU\", \"ER\"])]\n",
    "\n",
    "#create our plot \n",
    "ax = sns.lineplot(data=subset, x=\"Month\", y=\"Temp\", hue=\"Lake\", marker=\"o\")\n",
    "ax.set(title=\"Monthly Temp\", ylabel=\"Temp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd29ea6f-11d0-458a-a3e4-2bf36b196919",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68976c01-c540-4c2a-bd77-348dc59bae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = df[df[\"Lake\"].isin([\"SU\", \"ER\"])]\n",
    "ax = sns.lineplot(data=subset, x=\"Month\", y=\"Temp\", hue=\"Lake\", marker=\"^\")\n",
    "ax.set(title=\"Monthly Temp\", ylabel=\"Temp\")\n",
    "ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74688bb7",
   "metadata": {},
   "source": [
    "### 1.32 Distributions — histogram + KDE by Season\n",
    "**What:** Shape of temperatures.  \n",
    "**Why:** See multimodality & overlaps.  \n",
    "**How:** `histplot(stat=\"density\")` then optional `kdeplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7efc962-3348-41c8-b8a3-b47261516d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3459a6f-c1a4-4577-998e-5366fa0b8f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "df=pd.read_csv(\"../data/Temp_data_2010-2020.csv\")\n",
    "\n",
    "# 1) Ensure we have a proper Date \n",
    "df['Date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# 2) Get numeric month\n",
    "df['Month'] = df['Date'].dt.month\n",
    "\n",
    "# 3) Map month -> season (meteoro-logical), and make it an ordered categorical for nice plotting\n",
    "season_map = {\n",
    "    12: 'Winter', 1: 'Winter', 2: 'Winter',\n",
    "     3: 'Spring', 4: 'Spring', 5: 'Spring',\n",
    "     6: 'Summer', 7: 'Summer', 8: 'Summer',\n",
    "     9: 'Fall',  10: 'Fall',  11: 'Fall'\n",
    "}\n",
    "#pd.categorical allows us to specify the order of values in a column -- Like Factor in R\n",
    "df['Season'] = pd.Categorical(\n",
    "    df['Month'].map(season_map),\n",
    "    categories=['Winter','Spring','Summer','Fall'],\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# (optional) quick check\n",
    "print(df['Season'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb89d95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "\n",
    "sns.histplot(data=df, x='Temp_F', hue='Season', bins=24, stat='density', element='step', ax=ax)\n",
    "sns.kdeplot(data=df, x='Temp_F', hue='Season', common_norm=False, warn_singular=False, ax=ax)\n",
    "\n",
    "ax.set(title='Distribution of Temp (°F) by Season', xlabel='Temp (°F)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8511a9",
   "metadata": {},
   "source": [
    "### 1.33 Bar — mean Temp by Lake with error bars\n",
    "**What:** Group means with variability.  \n",
    "**Why:** Quick summary.  \n",
    "**How:** `estimator=np.mean`, `errorbar=\"sd\"` or `\"se\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bdafc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "\n",
    "sns.barplot(data=df, x='Lake', y='Temp_F', \n",
    "            estimator=np.mean, errorbar='sd', ax=ax, color=\"green\")\n",
    "\n",
    "ax.set(title='Mean Temp by Lake (±1 SD)', ylabel='Temp (°F)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3b6570",
   "metadata": {},
   "source": [
    "### 1.34 Pairplot\n",
    "Rule: sample ≤ 500 rows, `corner=True` to avoid redundancy.\n",
    "Take a small random sample so the pairplot is fast and readable.\n",
    "DataFrame.sample(...) returns a random subset of your rows (or columns). \n",
    "It’s perfect when a full dataset is too big/noisy to plot.\n",
    "We cap at 500 rows (or fewer if df has <500). random_state makes the sample reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7b36fe-ae8c-418a-b956-e906d6e623f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../data/Temp_data_2010-2020.csv\")\n",
    "\n",
    "# 1) Ensure we have a proper Date \n",
    "df['Date'] = pd.to_datetime(df['date'])\n",
    "# Create Day-of-Year\n",
    "df['DoY'] = df['Date'].dt.dayofyear\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60fa0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "small = df.sample(min(len(df), 500), random_state=0)\n",
    "# Pairwise relationships among the selected numeric columns.\n",
    "# - vars=... : which numeric columns to compare pairwise\n",
    "# - hue='Lake': color points by Lake category\n",
    "# - corner=True: show only the lower triangle + diagonal (less clutter)\n",
    "# - plot_kws: tweak the scatter markers (size=18, transparency=0.6) for visibility\n",
    "sns.pairplot(small, vars=['Temp','Temp_F','DoY'], hue='Lake', corner=True, plot_kws={'s':18, 'alpha':0.6})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb160e1e",
   "metadata": {},
   "source": [
    "### 1.35 Regression with confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ded431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One lake, one year: fit a simple curve over the season\n",
    "sub = df[(df['Year'] == 2018) & (df['Lake'] == 'MI')].dropna(subset=['DoY','Temp_F'])\n",
    "\n",
    "# 3) Plot a quadratic regression (order=2) to capture the arch-shaped seasonal pattern.\n",
    "#    - regplot is Axes-level (we pass in an Axes via matplotlib)\n",
    "#    - ci=95 shows a 95% confidence band around the fitted curve\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "sns.regplot(\n",
    "    data=sub, x='DoY', y='Temp_F',\n",
    "    order=2,              # quadratic trend (seasonal arch)\n",
    "    ci=95,                # confidence band for the fitted curve\n",
    "    scatter_kws={'s':18, 'alpha':0.4},\n",
    "    line_kws={'lw':2}\n",
    ")\n",
    "ax.set(title='Seasonal trend (MI, 2018)', xlabel='Day of Year', ylabel='Temp (°F)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63cf1d4",
   "metadata": {},
   "source": [
    "### 1.36 Violin + swarm (distribution per month, one lake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b15d306",
   "metadata": {},
   "outputs": [],
   "source": [
    "lake = 'MI'\n",
    "sub = df[df['Lake']==lake]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "sns.violinplot(data=sub, x='Month', y='Temp_F', inner=None, ax=ax, color=\"blue\",alpha=.4)\n",
    "sns.swarmplot(data=sub.sample(min(len(sub), 300), random_state=1), x='Month', y='Temp_F', size=2, color='k', alpha=.5, ax=ax)\n",
    "ax.set(title=f'{lake} Temp_F by Month', ylabel='Temp (°F)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07ab552-98dd-4598-8e96-75b449e53a54",
   "metadata": {},
   "source": [
    "### 1.37 Check-in [2] \n",
    "\n",
    "Import GLERL AMIC data and plot Annual Max Ice Coverga (AMIC)\n",
    "\n",
    "Goal: Make plots similar to those at https://www.glerl.noaa.gov/data/ice/#historical\n",
    "\n",
    "The data is in data/great_lakes_maxice.csv, \n",
    "\n",
    "make a Seaborn plot: x = Year (time), y = Ice Cover (%), facet per lake, get the bottom ticks to be like those in the GLERL plots. \n",
    "\n",
    "Your homework will be to import the raw data for now make a plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cd9b52-a4cc-412c-b65e-d457d93d0e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "amic = pd.read_csv(\"../data/great_lakes_maxice.csv\")\n",
    "\n",
    "amic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7563ae-caf5-479f-8ba4-49ef1651cb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code for your plot - focus on this if you finish early then work on the tick marks\n",
    "# you will need this for col_order in sns.relplot\n",
    "order = ['All_Lakes','Superior','Michigan','Huron','Erie','Ontario']\n",
    "\n",
    "# look up relplot and figure out how to use it - following the structure of previous examples\n",
    "# https://seaborn.pydata.org/generated/seaborn.relplot.html\n",
    "g = sns.relplot(\n",
    "    #look up the function and the different parameters call what you need\n",
    ")\n",
    "\n",
    "\n",
    "#I wrote this for you \n",
    "g.set_axis_labels(\"\", \"% ice coverage\").set_titles(\"AMIC - Lake {col_name}\")\n",
    "g.set(ylim=(0, 100))\n",
    "\n",
    "\n",
    "#your code for ticks if you have time \n",
    "\n",
    "#headings\n",
    "g.fig.suptitle(\"Great Lakes Annual Maximum Ice Cover (AMIC)\")\n",
    "g.fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698b9545-1ad4-43f9-9e07-9c9f8b07f638",
   "metadata": {},
   "outputs": [],
   "source": [
    "## the challenging part is getting the x-ticks right - see ref notebook from Day 5, google, chatgpt \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe1e740-7b38-4cff-a769-a78870f46afb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001a8c68-b9f7-42ea-bdc0-a85d8021c800",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = ['All_Lakes','Superior','Michigan','Huron','Erie','Ontario']\n",
    "\n",
    "g = sns.relplot(\n",
    "    data=amic, x=\"Year\", y=\"Cover\",\n",
    "    col=\"Lake\", col_order=order, col_wrap=2, kind=\"line\",\n",
    "    marker=\"o\", dashes=False, linewidth=1,\n",
    "    height=3, aspect=3.2, color=\"black\",\n",
    "    facet_kws={\"sharex\": True, \"sharey\": True}\n",
    ")\n",
    "g.set_axis_labels(\"\", \"% ice coverage\").set_titles(\"AMIC - Lake {col_name}\")\n",
    "g.set(ylim=(0, 100))\n",
    "\n",
    "## code for ticks\n",
    "min_year = int(amic['Year'].min())\n",
    "max_year = int(amic['Year'].max())\n",
    "years = np.arange(min_year, max_year + 1, 1)\n",
    "\n",
    "# First multiple of 5 >= min_year  → e.g., if min_year=1973, start_major=1975\n",
    "start_major = ((min_year + 4) // 5) * 5\n",
    "years_major = np.arange(start_major, max_year + 1, 5)\n",
    "\n",
    "for ax in g.axes.flatten():\n",
    "    # Major ticks every 5 years (labeled) starting at 1975 here\n",
    "    ax.set_xticks(years_major)\n",
    "    # Minor ticks every year (no labels), so you still \"see the ticks per year\"\n",
    "    ax.set_xticks(years, minor=True)\n",
    "\n",
    "    # Make sure bottom ticks show\n",
    "    ax.tick_params(axis=\"x\", which=\"both\", bottom=True)\n",
    "\n",
    "    # Style\n",
    "    ax.tick_params(axis=\"x\", which=\"major\", length=6, labelrotation=90)\n",
    "    ax.tick_params(axis=\"x\", which=\"minor\", length=3, labelbottom=False)\n",
    "\n",
    "g.fig.suptitle(\"Great Lakes Annual Maximum Ice Cover (AMIC)\")\n",
    "g.fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ef84ba",
   "metadata": {},
   "source": [
    "## 1.4 Reusable plotting functions\n",
    "Why functions? Reuse, composability (`ax=`), and clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612e913c",
   "metadata": {},
   "source": [
    "### 7.1 `plot_climatology`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bab841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_climatology(df, lakes=None, value='Temp_F', band='sd'):\n",
    "    \"\"\"\n",
    "    Plot monthly climatology (mean ± SD or SEM) for selected lakes.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame with columns 'Lake','Month' and the variable (e.g., Temp_F)\n",
    "    lakes : list of lake names to plot\n",
    "    value : str, column name of the variable to plot\n",
    "    band : 'sd' or 'sem(Standard Error of the Mean)' to choose variability measure\n",
    "    \"\"\"\n",
    "    # 1. Filter the data\n",
    "    use = df[df['Lake'].isin(lakes)]\n",
    "    \n",
    "    # 2. Compute mean, SD, SEM per month per lake\n",
    "    stats = (\n",
    "        use.groupby(['Lake', 'Month'])[value]\n",
    "        .agg(['mean', 'std', 'count'])\n",
    "        .reset_index()\n",
    "        .rename(columns={'mean': 'mean_val', 'std': 'sd_val', 'count': 'n'})\n",
    "    )\n",
    "    stats['sem_val'] = stats['sd_val'] / np.sqrt(stats['n'])\n",
    "    \n",
    "    # Choose band\n",
    "    if band == 'sem':\n",
    "        stats['band_val'] = stats['sem_val']\n",
    "    else:\n",
    "        stats['band_val'] = stats['sd_val']\n",
    "    \n",
    "    # 3. Plot\n",
    "    fig, ax = plt.subplots(figsize=(7, 4))\n",
    "    for lake in lakes:\n",
    "        sub = stats[stats['Lake'] == lake]\n",
    "        ax.plot(sub['Month'], sub['mean_val'], label=lake)\n",
    "        ax.fill_between(\n",
    "            sub['Month'],\n",
    "            sub['mean_val'] - sub['band_val'],\n",
    "            sub['mean_val'] + sub['band_val'],\n",
    "            alpha=0.2\n",
    "        )\n",
    "    \n",
    "    ax.set(\n",
    "        xlabel='Month',\n",
    "        ylabel=f'{value} (mean ± {band.upper()})',\n",
    "        title='Monthly Climatology'\n",
    "    )\n",
    "    ax.set_xticks(range(1, 13))\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #note we return ax -- so we could keep modifying it outseide \n",
    "    return ax\n",
    "\n",
    "plot_climatology(df, lakes=['ER','SU'], band='sd')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0059dacd-6e3a-4ef8-959b-a674d6aa7b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can call a new variable to hold our plot and make changes\n",
    "MI_temp=plot_climatology(df, lakes=['MI'], band='sd')\n",
    "MI_temp.set_title(\"Michigan only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bb9e0b",
   "metadata": {},
   "source": [
    "### 7.2 `plot_rolling_trend`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cf1a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rolling_trend(df, lake, year=None, value='Temp_F', window=7, anomaly=False):\n",
    "    \"\"\"Plot a rolling-mean time series for a lake (optionally filter to year); \n",
    "    optional anomaly vs monthly mean.\"\"\"\n",
    "    sub = df.loc[df['Lake']==lake,].copy()\n",
    "\n",
    "    # if year is teh default then all the data gets selected, otherwise only one year\n",
    "    if year is not None:\n",
    "        sub = sub.loc[sub['Year']==year,]\n",
    "    sub = sub.sort_values('Date')\n",
    "\n",
    "    ## if anomaly is true then we change the y-values to anomalies \n",
    "    ## relative to the monthly mean instead of plotting the raw values -- sub['Value'] changes\n",
    "    if anomaly == True:\n",
    "        clim = sub.groupby('Month')[value].transform('mean')\n",
    "        sub['Value'] = sub[value] - clim\n",
    "        ylab = f'{value} anomaly (vs monthly mean)'\n",
    "    else:\n",
    "        sub['Value'] = sub[value]\n",
    "        ylab = value\n",
    "    sub['Roll'] = sub['Value'].rolling(window, min_periods=max(3, window//2)).mean()\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(7,4))\n",
    "    ax.plot(sub['Date'], sub['Value'], alpha=.35, lw=1, label='daily')\n",
    "    ax.plot(sub['Date'], sub['Roll'], lw=2, label=f'rolling {window}d')\n",
    "    ax.set(xlabel='Date', ylabel=ylab, title=f'{lake} — rolling trend' + (f' ({year})' if year else ''))\n",
    "    ax.legend()\n",
    "    return ax\n",
    "\n",
    "## for one specific year, with anomaly as the default so false\n",
    "plot_rolling_trend(df, 'MI', year=2018, window=7); plt.tight_layout(); plt.show()\n",
    "\n",
    "## with all the years but anomaly is true\n",
    "plot_rolling_trend(df, 'HU', window=14, anomaly=True); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14a7559",
   "metadata": {},
   "source": [
    "### 7.4 `heatmap_year_month`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccdff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_year_month(df, lake, stats_wanted ='mean', value='Temp_F'):\n",
    "    piv = (df.loc[df['Lake']==lake]\n",
    "             .pivot_table(index='Year', columns='Month', values=value, aggfunc= stats_wanted))\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(7,4))\n",
    "    sns.heatmap(piv, cmap='coolwarm', cbar_kws={'label':f'{stats_wanted} {value}'}, linewidths=.3)\n",
    "    \n",
    "    \n",
    "    plt.title(f'{lake}: {value} by Year × Month')\n",
    "    plt.xlabel('Month'); plt.ylabel('Year')\n",
    "    plt.tight_layout()\n",
    "\n",
    "# Try it: different lake - try different stats - use a list ['max','min']\n",
    "heatmap_year_month(df, 'ER', stats_wanted = \"mean\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baeb6b5-278a-47e3-b174-b20485e0715e",
   "metadata": {},
   "source": [
    "# 2.0 [SciPy](https://docs.scipy.org/doc/scipy/reference/index.html)\n",
    "\n",
    "\"SciPy is a collection of mathematical algorithms and convenience functions built on the NumPy extension of Python.\" \n",
    "\n",
    "[Tutorial](https://scipy-lectures.org/packages/statistics/index.html)\n",
    "\n",
    "I don't have time to cover all of SciPy - below are quick examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb2a704-d78d-4518-93c0-aad5f73347bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##some libraries that allow is to run from stats \n",
    "import scipy\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4313cc17-c8fb-4f2b-abcf-6027bf775f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data=pd.read_csv(datadirectory+\"Temp_data_2010-2020.csv\")\n",
    "temp_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c965cb1d-1add-434f-ad73-732b446590b5",
   "metadata": {},
   "source": [
    "## 2.1 [t-test](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe64665-b8d7-4fde-bbfe-730657cc8177",
   "metadata": {},
   "outputs": [],
   "source": [
    "lake_SU=temp_data.loc[temp_data['Lake']=='SU','Temp_F']\n",
    "lake_ER=temp_data.loc[temp_data['Lake']=='ER','Temp_F']\n",
    "\n",
    "#one side- test value of a population mean\n",
    "print(stats.ttest_1samp(lake_SU, 0))\n",
    "\n",
    "#two sided- test diff across two populations\n",
    "print(stats.ttest_ind(lake_SU,lake_ER))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7368e6e4-005a-4af7-9cb7-271fb348b013",
   "metadata": {},
   "source": [
    "## 2.2 [KS Test](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ks_2samp.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7009ec-8c1c-423d-87b8-504d24462d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "\n",
    "lake_SU=temp_data.loc[temp_data['Lake']=='SU','Temp_F']\n",
    "lake_ER=temp_data.loc[temp_data['Lake']=='ER','Temp_F']\n",
    "\n",
    "print(stats.ks_2samp(lake_SU, lake_ER))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1747da95-f95b-41af-af64-b692fd4e1e4b",
   "metadata": {},
   "source": [
    "## 2.3 [One way Anova](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f_oneway.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dea7f9-e8ba-42ce-a76b-8ef57f699eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "lake_SU=temp_data.loc[temp_data['Lake']=='SU','Temp_F']\n",
    "lake_MI=temp_data.loc[temp_data['Lake']=='MI','Temp_F']\n",
    "lake_HU=temp_data.loc[temp_data['Lake']=='HU','Temp_F']\n",
    "lake_ER=temp_data.loc[temp_data['Lake']=='ER','Temp_F']\n",
    "lake_ON=temp_data.loc[temp_data['Lake']=='ON','Temp_F']\n",
    "\n",
    "F, p=f_oneway(lake_SU, lake_MI, lake_HU, lake_ER,lake_ON)\n",
    "print (F,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f195ff02-d23b-439f-833e-757966916388",
   "metadata": {},
   "source": [
    "## 2.4 [Linear Models](https://www.statsmodels.org/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb1f05c-3249-4bfc-9c2c-fb5b258ae140",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "\n",
    "selected_lake=temp_data.loc[temp_data['Lake']=='SU']\n",
    "\n",
    "model = ols(\"Temp_F ~ Day + Lake\", selected_lake).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a74b13-2cc7-43b4-8443-107e96c4428a",
   "metadata": {},
   "source": [
    "## 2.5 with Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650de751-f00d-4390-aa48-aed0bf07353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3d9350-6049-498f-a3a9-e57abc58b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Pick a lake and get the data\n",
    "lake = \"Erie\"  # change me\n",
    "sub = amic.loc[amic[\"Lake\"] == lake].sort_values(\"Year\")\n",
    "\n",
    "x = sub[\"Year\"].to_numpy()\n",
    "y = sub[\"Cover\"].to_numpy()\n",
    "\n",
    "# 2) Run SciPy linear regression\n",
    "res = linregress(x, y)\n",
    "slope, intercept, r, p, stderr = res.slope, res.intercept, res.rvalue, res.pvalue, res.stderr\n",
    "r2 = r**2\n",
    "\n",
    "# 3) Build the fitted line on a dense x-grid (looks nicer)\n",
    "x_fit = np.linspace(x.min(), x.max(), 200)\n",
    "y_fit = intercept + slope * x_fit\n",
    "\n",
    "# 4) Plot data + fit\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.scatter(x, y, s=30, alpha=0.8, label=\"Annual ice cover\")\n",
    "ax.plot(x_fit, y_fit, lw=2, label=\"Linear fit\", color=\"red\")\n",
    "\n",
    "# 5) Add an annotation box with stats (axes coords so it stays in corner)\n",
    "ax.text(\n",
    "    0.02, 0.68,\n",
    "    f\"Lake {lake}\\n\"\n",
    "    f\"y = {intercept:.2f} + {slope:.3f}·Year\\n\"\n",
    "    f\"$R^2$ = {r2:.3f},  p = {p:.3g}\",\n",
    "    transform=ax.transAxes, va=\"top\", ha=\"left\",\n",
    "    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8)\n",
    ")\n",
    "\n",
    "ax.set(\n",
    "    xlabel=\"Year\",\n",
    "    ylabel=\"Ice cover (%)\",\n",
    "    title=f\"Trend in annual ice cover — {lake}\"\n",
    ")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac478ee2-7c9e-49eb-8929-2131f3e11b42",
   "metadata": {},
   "source": [
    "## 2.6 Check-in [3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe41822c-0215-4e6d-a145-14feae03f6e8",
   "metadata": {},
   "source": [
    "Question: Are the daily temperature distributions different between Lake Erie (ER) and Lake Superior (SU)?\n",
    "\n",
    "Use the two-sample Kolmogorov–Smirnov test (scipy.stats.ks_2samp) at α = 0.05.\n",
    "\n",
    "Show a boxplot (quick summary).\n",
    "\n",
    "Report: D, p-value, and sample sizes.\n",
    "\n",
    "Briefly interpret: “Reject/Fail to reject the null that the two distributions are the same.”\n",
    "(Note: KS tells you they differ, not which is warmer— need medians/means if you want direction.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8617a7-16bb-424a-ba17-fae1ff6cd93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=pd.read_csv(\"../data/Temp_data_2010-2020.csv\")\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bc447c-4113-441f-b703-62b661ecfa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select data\n",
    "\n",
    "\n",
    "#quick boxplots\n",
    "\n",
    "\n",
    "# KS test (two-sample, nonparametric)\n",
    "\n",
    "\n",
    "# Annotate stats on the plot -- if time allows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87b591b-0084-43a9-80a8-70a2f8d30fac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf838292-da27-4daa-b6c3-24a4187c3057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select data\n",
    "sub = temp.loc[temp[\"Lake\"].isin([\"ER\", \"SU\"])].copy()\n",
    "\n",
    "#quick boxplots\n",
    "ax = sns.boxplot(data=sub, x=\"Lake\", y=\"Temp_F\")\n",
    "ax.set(title=\"Daily Temperature — ER vs SU\", xlabel=\"Lake\", ylabel=\"Temp (°F)\")\n",
    "\n",
    "# KS test (two-sample, nonparametric)\n",
    "er = sub.loc[sub[\"Lake\"] == \"ER\", \"Temp_F\"]\n",
    "su = sub.loc[sub[\"Lake\"] == \"SU\", \"Temp_F\"]\n",
    "\n",
    "D, p = ks_2samp(er, su, alternative=\"two-sided\", mode=\"auto\")\n",
    "print(f\"KS two-sample: D={D:.3f}, p={p:.3g} | n_ER={er.size}, n_SU={su.size}\")\n",
    "\n",
    "# Annotate stats on the plot\n",
    "ax.text(\n",
    "    0.02, 0.95,\n",
    "    f\"D={D:.3f}\\np={p:.3g}\",\n",
    "    transform=ax.transAxes, ha=\"left\", va=\"top\",\n",
    "    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.85)\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4578108",
   "metadata": {},
   "source": [
    "# 3.0 Map basics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0519289-82d8-4642-8cb3-e5a3605864aa",
   "metadata": {},
   "source": [
    "[CartoPy and GeoPandas](https://fneum.github.io/data-science-for-esm/04-workshop-geopandas.html) are two popular ways to make maps with Python. \n",
    "\n",
    "CartoPy is great for making publication ready maps with final data where you can chnage every aspect of the map.\n",
    "GeoPandas is great for data processing, manipulation, then plots. \n",
    "\n",
    "The two can work together. \n",
    "Below is a short description of each.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a176192-e8ac-4c19-82b4-ebd327203604",
   "metadata": {},
   "source": [
    "## 3.1 CartoPy\n",
    "\n",
    "**[Cartopy](https://scitools.org.uk/cartopy/docs/latest/)** Python library for maps.\n",
    "\n",
    "-**[Good Cartopy Intro](https://rabernat.github.io/research_computing_2018/maps-with-cartopy.html)**\n",
    "\n",
    "-**[Good Tutorial](https://coderzcolumn.com/tutorials/data-science/cartopy-basic-maps-scatter-map-bubble-map-and-connection-map)**\n",
    "\n",
    "-**[List of Cartopy Projections](https://scitools.org.uk/cartopy/docs/v0.15/crs/projections.html)**\n",
    "\n",
    "[cartopy git page](https://github.com/SciTools/cartopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74206d92-ce3d-4d2d-9fba-78e3d937b036",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for colors\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b941a4e3-e4a0-4b3f-925e-35ee28bc360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "# this cartopy version was released about 25days ago 8/28 \n",
    "# so there are many warnings that will eventually be silenced\n",
    "print (cartopy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537389e1-0df4-420d-ad23-1932b052ab7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new figure and add on via ax\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "#we will add a projection of the map to ax then add to it\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f504291-5ae8-4ea3-aa21-40ce5a1cc485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the size of our figure frame\n",
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "#flat projection\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "#add coastline\n",
    "ax.coastlines()\n",
    "#add countries -- the larger scale for borders triggers a warning \n",
    "ax.add_feature(cfeature.BORDERS.with_scale(\"50m\"), linestyle=\"-\")\n",
    "#add lakes\n",
    "ax.add_feature(cfeature.LAKES.with_scale(\"50m\"), facecolor=\"blue\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cf92a8-c114-4193-a948-4d685e10a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "#more realistic spherical projection\n",
    "ax = plt.axes(projection=ccrs.Orthographic())\n",
    "\n",
    "#add coastline\n",
    "ax.coastlines(color=\"black\")\n",
    "#add ocean\n",
    "ax.add_feature(cartopy.feature.OCEAN,facecolor='skyblue')\n",
    "\n",
    "#add countries\n",
    "ax.add_feature(cfeature.BORDERS,facecolor='white',edgecolor='white')\n",
    "#add land\n",
    "ax.add_feature(cartopy.feature.LAND,facecolor=\"green\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0321ad4-4957-4003-ac1d-a3af4d57414b",
   "metadata": {},
   "source": [
    "Let's look at the places were Maria has sampled on the Great Lakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fdcbee-31a4-4c10-8968-aa0b4d232323",
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_stations=pd.read_csv(datadirectory+'gl_stations.csv')\n",
    "gl_stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08203924-8649-4a36-a6ec-6327f3cd5e45",
   "metadata": {},
   "source": [
    "**RuntimeWarning** is coming from Natural Earth geometries (most often LAKES or RIVERS) that contain empties/NaNs/invalid rings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1c8ba2-e1d3-4b34-9cb5-020390179fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the center points based on the mean of the points I do have\n",
    "central_lat = gl_stations['LATITUDE'].mean()\n",
    "central_lon = gl_stations['LONGITUDE'].mean()\n",
    "\n",
    "#extent is the [west_point,east_point,south_point,north_point]\n",
    "extent = [gl_stations['LONGITUDE'].min()-2, gl_stations['LONGITUDE'].max()+2,\n",
    "          gl_stations['LATITUDE'].min()-2, gl_stations['LATITUDE'].max()+2]\n",
    "\n",
    "#create a figure\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = plt.axes(projection=ccrs.Orthographic(central_lon, central_lat))\n",
    "ax.set_extent(extent)\n",
    "\n",
    "#add features\n",
    "ax.add_feature(cartopy.feature.LAKES.with_scale('50m'),edgecolor='black')\n",
    "ax.add_feature(cartopy.feature.RIVERS.with_scale('50m'))\n",
    "\n",
    "#setting labels to true will give me labels on x and y axis\n",
    "ax.gridlines(draw_labels=True)\n",
    "\n",
    "##add multiple points -- to add multiple points we use scatteplot but we must pass crs.PlateCarree() in transform,\n",
    "#maybe there are other ways but this is teh only way it works for me\n",
    "ax.scatter(x=gl_stations.LONGITUDE, y=gl_stations.LATITUDE,color=\"red\",\n",
    "            s=30,alpha=0.8,transform=ccrs.PlateCarree(),zorder=2)\n",
    "\n",
    "##### THE Z-ORDER is the order in which layers are shown where 0 is first and the higher is on top, I called zorder to 2 so I could see my points \n",
    "\n",
    "#add labels\n",
    "ax.set_title('LAURENTIAN GREAT LAKES: EPA SAMPLING STATIONS')\n",
    "\n",
    "#I save most of my figures as .pdf until I'm ready to make manuscript figures\n",
    "#you can save your plots whiever way you prefer, same commands as other plots \n",
    "plt.savefig(data_out_directory+'gl_map.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcbcea1-1975-4a70-ba5a-4d0c1183f91c",
   "metadata": {},
   "source": [
    "Plotting over land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429e2774-0e0b-4d72-8235-0b54ffdd53be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chicago coordinates\n",
    "lon, lat = -87.6298, 41.8781\n",
    "\n",
    "# Use PlateCarree (lon/lat degrees)\n",
    "proj = ccrs.PlateCarree()\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = plt.axes(projection=proj)\n",
    "\n",
    "# Add base map features\n",
    "ax.add_feature(cfeature.LAND.with_scale('50m'), facecolor=\"lightgrey\")\n",
    "ax.add_feature(cfeature.BORDERS.with_scale('50m'), linewidth=0.5)\n",
    "ax.add_feature(cfeature.COASTLINE.with_scale('50m'), linewidth=0.5)\n",
    "ax.add_feature(cfeature.STATES.with_scale(\"50m\"), linewidth=0.4)\n",
    "\n",
    "# Plot Chicago as a point\n",
    "ax.plot(lon, lat, marker=\"o\", color=\"maroon\", markersize=8,\n",
    "        transform=proj, zorder=3)\n",
    "\n",
    "# Add label\n",
    "ax.text(lon+3, lat+1, \"Chicago\", transform=proj,\n",
    "        fontsize=10, weight=\"bold\")\n",
    "\n",
    "# Zoom roughly to US\n",
    "ax.set_extent([-130, -60, 20, 55], crs=proj)\n",
    "\n",
    "ax.set_title(\"Where are we?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c35719f-5a1d-49b5-8cf7-0c2ca3d40dc6",
   "metadata": {},
   "source": [
    "## 3.2 GeoPandas \n",
    "\n",
    "[GeoPandas Tutorial](https://www.datacamp.com/tutorial/geopandas-tutorial-geospatial-analysis)\n",
    "\n",
    "[Natural Earth Maps](https://www.naturalearthdata.com/downloads/) #Basefiles you can download\n",
    "\n",
    "[GeoPandas Projections](https://geopandas.org/en/stable/docs/user_guide/projections.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca28d3ab-2ca6-4966-92d1-53cd47e1a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941e85df-9df8-4a20-b2a3-871d52e38360",
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_stations = pd.read_csv(\"../data/gl_stations.csv\") \n",
    "gl_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc456504-f3b9-4cf0-852c-33381efe8c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we have to reformat the lat/long into points that geopnadas can recognize\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    gl_stations,\n",
    "    geometry=gpd.points_from_xy(gl_stations[\"LONGITUDE\"], gl_stations[\"LATITUDE\"]),\n",
    "    crs=\"EPSG:4326\"   # lon/lat (WGS84)\n",
    ")\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4c2199-2a6f-4e7d-be39-e0d5cef2c60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lakes_url = \"https://naturalearth.s3.amazonaws.com/10m_physical/ne_10m_lakes.zip\"\n",
    "#lakes = gpd.read_file(lakes_url)\n",
    "\n",
    "lakes = gpd.read_file('../data/ne_10m_lake.zip')\n",
    "lakes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e375e1d-52d6-4bc3-aae8-433eaee769cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Choose just the five Laurentian Great Lakes by name\n",
    "keep = [\"Lake Superior\",\"Lake Michigan\",\"Lake Huron\",\"Lake Erie\",\"Lake Ontario\"]\n",
    "great_lakes = lakes[lakes[\"name\"].isin(keep)].copy()\n",
    "\n",
    "# 2) Define a projection/CRS suitable for the Great Lakes region\n",
    "#    EPSG:3175 = NAD83 / Great Lakes Albers (equal-area)\n",
    "crs_gl = \"EPSG:3175\"  # Great Lakes Albers (equal-area)\n",
    "\n",
    "# 3) Reproject both polygons (lakes) and points (stations) into this CRS\n",
    "gl_poly = great_lakes.to_crs(crs_gl) #lake\n",
    "gl_pts  = gdf.to_crs(crs_gl) #points\n",
    "\n",
    "# 4) Create a Matplotlib figure + axis\n",
    "fig, ax = plt.subplots(figsize=(7,6))\n",
    "\n",
    "# 5) Plot the lakes as filled blue polygons with black borders\n",
    "gl_poly.plot(ax=ax, color=\"#cfe8ff\", edgecolor=\"k\", linewidth=0.5)\n",
    "\n",
    "# 6) Plot the station points in red on top\n",
    "gl_pts.plot(ax=ax, color=\"crimson\", markersize=16, alpha=0.9)\n",
    "\n",
    "#make pretty and safe \n",
    "ax.set_title(\"LAURENTIAN GREAT LAKES: EPA SAMPLING STATIONS\", pad=8)\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f248f6-bbb4-4453-957c-faf3c323f226",
   "metadata": {},
   "source": [
    "For land:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa108e2-2f69-4b3d-8687-0b2a791b3753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basemap\n",
    "world = gpd.read_file(\"../data/ne_110m_admin_0_countries.zip\")\n",
    "\n",
    "world.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880b3a19-47a7-4a14-8547-c240e38b9997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Chicago point (lon, lat)\n",
    "chi = gpd.GeoDataFrame(\n",
    "    {\"City\": [\"Chicago\"]},\n",
    "    geometry=[Point(-87.6298, 41.8781)],   # (lon, lat)\n",
    "    crs=\"EPSG:4326\" #projection\n",
    ")\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "world.plot(ax=ax, color=\"lightgrey\", edgecolor=\"white\")\n",
    "\n",
    "# Add the city\n",
    "chi.plot(ax=ax, color=\"maroon\", markersize=60)\n",
    "\n",
    "# Add a text label just offset from the point\n",
    "for x, y, label in zip(chi.geometry.x, chi.geometry.y, chi[\"City\"]):\n",
    "    ax.text(x+2, y+1, label, fontsize=10, weight=\"bold\")\n",
    "\n",
    "ax.set_xlim([-130, -60])  # zoom roughly to US\n",
    "ax.set_ylim([20, 55])\n",
    "ax.set_title(\"Where are we?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fbfc7d-9edd-45ce-9bb0-9d0945d1f104",
   "metadata": {},
   "source": [
    "## 3.3 Check-in [4]\n",
    "Make a map with three cities of your choice. \n",
    "Fill in the ? in the code below.\n",
    "Use whatever method you want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663f51e9-69f9-4ce3-b511-308ef671cc33",
   "metadata": {},
   "source": [
    "add your points here - the ? should be lists with your values\n",
    "I want three cities you choose, and use google maps to get lat/lon\n",
    "\n",
    "```python\n",
    "my_df=pd.DataFrame({'City':[?],\n",
    "                   'Lat':[?],\n",
    "                   'Lon':[?]})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996fa028-505c-40bf-b63a-3081508adf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your map code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838d45ee-35e7-4b55-a503-e44404115022",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6a0706-7e5a-4ac6-8aa4-51ab1b55722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame({\n",
    "    'City': ['London', 'Seoul', 'Mexico City'],\n",
    "    'Lat':  [51.5074,   37.5665,  19.4326],\n",
    "    'Lon':  [-0.1278,  126.9780, -99.1332]\n",
    "})\n",
    "\n",
    "proj = ccrs.PlateCarree()  # data are lon/lat degrees\n",
    "fig = plt.figure(figsize=(8, 4.8))\n",
    "ax = plt.axes(projection=proj)\n",
    "\n",
    "# Basemap features\n",
    "ax.add_feature(cfeature.LAND.with_scale('50m'), facecolor='#f2f2f2')\n",
    "ax.add_feature(cfeature.OCEAN.with_scale('50m'), facecolor='#e6f3ff')\n",
    "ax.add_feature(cfeature.BORDERS.with_scale('50m'), linewidth=0.4)\n",
    "ax.coastlines(resolution='110m', linewidth=0.6)\n",
    "\n",
    "# Gridlines with labels (cartopy handles °E/°W/°N/°S)\n",
    "gl = ax.gridlines(draw_labels=True, x_inline=False, \n",
    "                  y_inline=False, linewidth=0.5, color='0.7', linestyle=':')\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "\n",
    "# Points (note: transform=PlateCarree because Lon/Lat)\n",
    "ax.scatter(my_df['Lon'], my_df['Lat'], transform=proj,\n",
    "           color='crimson', s=40, edgecolor='white', linewidth=0.6, zorder=3)\n",
    "\n",
    "# Labels\n",
    "for _, r in my_df.iterrows():\n",
    "    ax.text(r['Lon'] + 5, r['Lat'] + 3, r['City'], transform=proj,\n",
    "            fontsize=10, weight='bold')\n",
    "\n",
    "ax.set_global()  # show the world\n",
    "ax.set_title('Three Cities (Cartopy)', pad=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380669e6-c626-4be4-a6bd-ca7cd1675ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basemap\n",
    "world = gpd.read_file(\"../data/ne_110m_admin_0_countries.zip\")\n",
    "\n",
    "# 1) Sample cities\n",
    "my_df = pd.DataFrame({\n",
    "    'City': ['London', 'Seoul', 'Mexico City'],\n",
    "    'Lat':  [51.5074,   37.5665,  19.4326],\n",
    "    'Lon':  [-0.1278,  126.9780, -99.1332]\n",
    "})\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    my_df,\n",
    "    geometry=gpd.points_from_xy(my_df['Lon'], my_df['Lat']),\n",
    "    crs=\"EPSG:4326\"   # WGS84 lat/lon\n",
    ")\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "world.plot(ax=ax, color=\"lightgrey\", edgecolor=\"white\")\n",
    "gdf.plot(ax=ax, color=\"crimson\", markersize=60)\n",
    "\n",
    "# Add city labels\n",
    "for x, y, label in zip(gdf.geometry.x, gdf.geometry.y, gdf[\"City\"]):\n",
    "    ax.text(x+3, y+2, label, fontsize=9, weight=\"bold\")\n",
    "\n",
    "ax.set_title(\"Three Cities (GeoPandas)\", pad=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32d261b",
   "metadata": {},
   "source": [
    "# 4.0 Quick animation example -> GIF\n",
    "A gif is a movie, and for movies we need frames that move as a specific speed. We can thus make gifs by combining many frames that we make."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284935da-1fa3-4554-b86c-217cbde24584",
   "metadata": {},
   "source": [
    "Eric has a great tutorial [here](https://www.ericvc.com/codes/Animation_Example.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8320a7-eb92-4527-94d3-9783b6b5d966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation, PillowWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22d7bf6-6360-4c99-ad65-e551dafaed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../data/Temp_data_2010-2020.csv\")\n",
    "\n",
    "# 1) Ensure we have a proper Date \n",
    "df['Date'] = pd.to_datetime(df['date'])\n",
    "# Create Day-of-Year\n",
    "df['DoY'] = df['Date'].dt.dayofyear\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d062b62f-0c6e-4a06-b671-e2664226ebf6",
   "metadata": {},
   "source": [
    "**Select the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b29407-fefa-4b9d-a37e-ddb914eab3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the dat from frames\n",
    "lake = 'MI' \n",
    "year = 2019\n",
    "sub = df[(df['Lake']==lake) & (df['Year']==year)].sort_values('Date')\n",
    "\n",
    "#data arrays - we will make frames with each - this \n",
    "x = sub['Date'].to_numpy()\n",
    "y = sub['Temp_F'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c8f559-901a-449c-98ea-df253f368b6d",
   "metadata": {},
   "source": [
    "**Create a blank figure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dea634-a139-467d-985b-c7bb534ae67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a new figure (canvas) and one subplot (ax)\n",
    "# figsize sets the width=7 inches and height=4 inches\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "\n",
    "# Set axis labels and a title\n",
    "# f-string lets you insert variable values (lake, year) into the title\n",
    "ax.set(xlabel='Date', ylabel='Temp (°F)', title=f'{lake} daily Temp — {year}')\n",
    "\n",
    "# Set the x-axis and y-axis ranges\n",
    "# Here x and y are assumed to be arrays of your data\n",
    "# We expand the y-limits by ±2 for nicer spacing\n",
    "ax.set_xlim(x.min(), x.max())\n",
    "ax.set_ylim(y.min()-2, y.max()+2)\n",
    "\n",
    "# Initialize a line object (empty plot for now) with line width = 2\n",
    "# The comma is needed to unpack the single-element tuple that plt.plot returns\n",
    "(line,) = ax.plot([], [], lw=2)\n",
    "\n",
    "#show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87240e72-b7ed-421e-81d1-77cca8cf64ca",
   "metadata": {},
   "source": [
    "**create multiple frames and combine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec67408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the initialization function for the animation\n",
    "# This runs once at the start: clears the line\n",
    "def init():\n",
    "    line.set_data([], [])       # set empty data for x and y\n",
    "    return (line,)              # return the line object (must be iterable)\n",
    "\n",
    "# Define the update function for each frame\n",
    "# i = current frame index (0, 1, 2, …)\n",
    "def update(i):\n",
    "    line.set_data(x[:i], y[:i]) # plot data up to frame i\n",
    "    return (line,)              # return the updated line object\n",
    "    \n",
    "# Create the animation object\n",
    "# - fig: the figure to draw on\n",
    "# - update: called each frame -- the function we made above \n",
    "# - frames=len(x): number of frames in the animation\n",
    "# - init_func=init: how to reset at start\n",
    "# - blit=True: only redraw parts that change (faster)\n",
    "anim = FuncAnimation(fig, update, frames=len(x), init_func=init, blit=True)\n",
    "\n",
    "# Save the animation as a GIF (12 frames per second)\n",
    "anim.save('../output/temp_trend.gif', writer=PillowWriter(fps=12))\n",
    "\n",
    "# Close the figure to avoid duplicate static plot display and save memory\n",
    "plt.close(fig)\n",
    "\n",
    "#to confirm our plot is done\n",
    "#open in browser\n",
    "print(\"Saved GIF -> temp_trend.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f49424d-32da-46e6-9c50-fec25cdf4a0d",
   "metadata": {},
   "source": [
    "**Together**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d732518-2f3f-42a7-9628-b6108e247bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the data for one lake and year\n",
    "lake = 'MI' \n",
    "year = 2019\n",
    "sub = df[(df['Lake']==lake) & (df['Year']==year)].sort_values('Date')\n",
    "\n",
    "# Convert to numpy arrays\n",
    "x = sub['Date'].to_numpy()\n",
    "y = sub['Temp_F'].to_numpy()\n",
    "\n",
    "# Create a new figure (canvas) and one subplot (ax)\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "\n",
    "# Set axis labels and a title\n",
    "ax.set(xlabel='Date', ylabel='Temp (°F)', title=f'{lake} daily Temp — {year}')\n",
    "\n",
    "# Set axis ranges\n",
    "ax.set_xlim(x.min(), x.max())\n",
    "ax.set_ylim(y.min()-2, y.max()+2)\n",
    "\n",
    "# Initialize a line object (empty for now)\n",
    "(line,) = ax.plot([], [], lw=2)\n",
    "\n",
    "# Define the initialization function (clears the line at the start)\n",
    "def init():\n",
    "    line.set_data([], [])\n",
    "    return (line,)\n",
    "\n",
    "# Define the update function (called for each frame)\n",
    "def update(i):\n",
    "    line.set_data(x[:i], y[:i])\n",
    "    return (line,)\n",
    "\n",
    "# Create the animation object\n",
    "anim = FuncAnimation(\n",
    "    fig, update, frames=len(x),\n",
    "    init_func=init, blit=True\n",
    ")\n",
    "\n",
    "# Save the animation as a GIF (12 frames per second)\n",
    "anim.save('../output/temp_trend.gif', writer=PillowWriter(fps=12))\n",
    "\n",
    "\n",
    "# Close the figure to avoid duplicate static plot display\n",
    "plt.close(fig)\n",
    "\n",
    "# Confirm completion\n",
    "print(\"Saved GIF -> temp_trend.gif\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb55654-0ea9-40f6-a282-d87d9288b303",
   "metadata": {},
   "source": [
    "## Check-in [5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a50794-5fe3-440b-8e20-0d2e1b150af6",
   "metadata": {},
   "source": [
    "Make a .gif for lake supeior annual max ice cover! The code you need is identical to what you have above you just need to make a couple of changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff26d537-43bf-4826-a555-f5f0e14c6735",
   "metadata": {},
   "outputs": [],
   "source": [
    "amic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a405d456-78d9-48a6-abbd-4b9cb4799ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick lake & subset\n",
    "\n",
    "# Figure & empty line\n",
    "\n",
    "# Animation callbacks\n",
    "\n",
    "# Create the animation object\n",
    "\n",
    "# Save the animation as a GIF\n",
    "\n",
    "# Close the figure to avoid duplicate static plot display\n",
    "\n",
    "# Confirm completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73b40d4-5847-48d9-95e0-fcdf57b1220d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bb9aeb-6395-4086-b88e-4a7f6bc990e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick lake & subset\n",
    "lake = \"Superior\"  \n",
    "sub = amic.loc[amic[\"Lake\"] == lake].sort_values(\"Year\")\n",
    "\n",
    "# Data arrays\n",
    "x = sub[\"Year\"].values\n",
    "y = sub[\"Cover\"].values  \n",
    "\n",
    "# Figure & empty line\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.set(xlabel=\"Year\", ylabel=\"Ice Cover (%)\", title=f\"Annual Ice Cover — Lake {lake}\")\n",
    "\n",
    "ax.set_xlim(x.min(), x.max())\n",
    "ax.set_ylim(y.min() - 2, y.max() + 2)\n",
    "(line,) = ax.plot([], [], lw=2, marker=\"o\")\n",
    "\n",
    "# Animation callbacks\n",
    "def init():\n",
    "    line.set_data([], [])\n",
    "    return (line,)\n",
    "\n",
    "def update(i):\n",
    "    line.set_data(x[:i], y[:i])  \n",
    "    return (line,)\n",
    "\n",
    "#creat amim\n",
    "anim = FuncAnimation(fig, update, frames=range(1, len(x)+1), init_func=init, blit=True)\n",
    "\n",
    "# Save GIF to current folder (no os needed)\n",
    "anim.save(f'../output/{lake}_amic_trend.gif', writer=PillowWriter(fps=8))\n",
    "plt.close(fig)\n",
    "print(f\"Saved GIF -> {lake}_amic_trend\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273fa9ea-eaa9-4d09-947c-3f0178792ccb",
   "metadata": {},
   "source": [
    "# 5.0 Summary\n",
    "Today I showed you the following:\n",
    "\n",
    "1. Explore data with the seaborn plotting library\n",
    "2. Make figures with AxesSubplot and FacetGrid\n",
    "3. Using for loops for complicated subplots \n",
    "4. Maps\n",
    "5. Gifs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd06c222-f73b-45f7-8e0e-81b2d3b8f496",
   "metadata": {},
   "source": [
    "# 6.0 Self- eval\n",
    "Use this space to write future notes for your self. \n",
    "- What is something you found useful/cool? \n",
    "- What is something you don't quite understand and need to follow up with TAs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee5b19b-ecc9-431c-bc9e-b211217a7c40",
   "metadata": {},
   "source": [
    "# Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1ba959-de8a-460c-a9db-57b5b0cc35d9",
   "metadata": {},
   "source": [
    "## Problem 1 - Seaborn Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785266f0-d12f-46a2-a049-1e1449fba157",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=pd.read_csv(datadirectory+\"Temp_data_2010-2020.csv\")\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469cab5b-3869-4a3b-aeb2-1e1a401c5dad",
   "metadata": {},
   "source": [
    "### A) for lake Michigan plot boxplots that show the monthly temp distribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb2d26-31be-4bd1-83e1-941bcc086e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code using boxplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece4e2ad-b84b-4e95-9595-18c9218ebdcb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f95a25a-7863-40ab-8306-10c85c71415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lake = \"MI\"\n",
    "sub = temp[temp[\"Lake\"] == lake].copy()\n",
    "\n",
    "ax = sns.boxplot(data=sub, x=\"Month\", y=\"Temp_F\")\n",
    "ax.set(title=f\"Monthly Daily Temperatures — {lake}\", xlabel=\"Month\", ylabel=\"Temp (°F)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d54a3c-8fe3-42ff-a108-178157211d07",
   "metadata": {},
   "source": [
    "### B) but it would be nice to see all the lakes and only do this once! explore using catplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71258467-045a-471e-baa7-18fd5c4ef706",
   "metadata": {},
   "outputs": [],
   "source": [
    "## look up and use sns.catplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f02d959-782d-4a0d-8f05-93aa1e195686",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85220523-bcb7-4c0a-8209-fffe0122774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    data=temp,\n",
    "    x=\"Month\", y=\"Temp_F\",\n",
    "    kind=\"box\",\n",
    "    col=\"Lake\",            # one small panel per lake\n",
    "    col_wrap=3,            # wrap into rows if many lakes\n",
    "    height=3.2, aspect=1.2,\n",
    "    sharey=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572c5564-2800-49f3-9a83-a1f5b289613e",
   "metadata": {},
   "source": [
    "## Problem 2 - SciPy\n",
    "\n",
    "For a chosen lake, test whether January vs July daily temperatures differ (Welch’s t-test). Print t-stat and p-value and a one-line interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a0ba2d-86ca-40e3-9649-da16209977d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0930c2c-4a36-434c-85a2-82004c4a29b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "## your work \n",
    "## use temp data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec31347-3235-4b3b-a57f-9f5fb60397b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a952cf5d-2973-4e80-abe8-4037aa583c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "lake = \"ER\"\n",
    "sub = temp[temp[\"Lake\"] == lake].copy()\n",
    "\n",
    "jan = sub.loc[sub[\"Month\"] == 1, \"Temp_F\"]\n",
    "jul = sub.loc[sub[\"Month\"] == 7, \"Temp_F\"]\n",
    "\n",
    "tstat, p = ttest_ind(jan, jul, equal_var=False, nan_policy=\"omit\")\n",
    "print(f\"Welch t-test (Jan vs Jul) — {lake}: t={tstat:.3f}, p={p:.3g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a204118b-78c3-43bf-aace-578dab18984a",
   "metadata": {},
   "source": [
    "## Problem 3* - Processing AMIC raw data. [difficult]\n",
    "\n",
    "The data from great lakes max ice live here: \n",
    "url = \"https://www.glerl.noaa.gov/data/ice/glicd/dates_AMIC.txt\"\n",
    "\n",
    "import and clean it \n",
    "your goal is to recreate great_lakes_maxice.csv that I made for you!!\n",
    "\n",
    "Work with chatGPT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6233a5-db9e-41df-a145-7aa148a86c88",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Import required libraries (showing students what we need)\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import numpy as np\n",
    "    from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88f8969-1ddf-4700-914b-95866daf415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code\n",
    "## note the number of columns in the first rows is a mess that will be the biggest challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cc32a5-81a7-45a9-aeb0-540b0553d64a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525a09ad-ff60-47ae-a8a1-f630583510dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.glerl.noaa.gov/data/ice/glicd/dates_AMIC.txt\"\n",
    "\n",
    "# Lakes in file order\n",
    "lakes = [\"Superior\", \"Michigan\", \"Huron\", \"Erie\", \"Ontario\", \"All_Lakes\"]\n",
    "\n",
    "# Interleaved names: Year, (cover,date) × 6 lakes\n",
    "names = [\"Year\"] + [f\"{lk}_{k}\" for lk in lakes for k in (\"cover\",\"date\")]\n",
    "# We only want the first 13 columns: Year + 12 lake tokens (skip trailing duplicate Year)\n",
    "usecols = list(range(13))\n",
    "\n",
    "# Read:\n",
    "# - skiprows=2 → drop the two header lines\n",
    "# - usecols=range(13) → keep only cols 0..12 (skip trailing Year at col 13)\n",
    "# - sep=r\"\\s+\" → whitespace-delimited\n",
    "# - dtype=str first (forgiving), then we'll coerce types\n",
    "raw = pd.read_csv(\n",
    "    url,\n",
    "    sep=r\"\\s+\",\n",
    "    engine=\"python\",\n",
    "    header=None,\n",
    "    names=names,\n",
    "    skiprows=2,\n",
    "    usecols=range(13),\n",
    "    dtype=str,\n",
    "    skip_blank_lines=True,\n",
    ")\n",
    "\n",
    "#drop columns with _date because we don't need them and it will make it easier to melt this table to long format\n",
    "raw = raw.drop(columns=[c for c in raw.columns if c.endswith(\"_date\")])\n",
    "\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea90d99a-bd0d-49e3-91b8-3cad0a3dc54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## let use melt\n",
    "amic = (\n",
    "    raw.melt(id_vars=\"Year\",            # keep Year as-is\n",
    "             var_name=\"Lake\",           # old column names go here\n",
    "             value_name=\"Cover\")        # this will be the new name for col with values\n",
    ")\n",
    "\n",
    "# Clean up \"Lake\" so it’s just the lake name, not \"x_cover\"\n",
    "amic[\"Lake\"] = amic[\"Lake\"].str.replace(\"_cover\", \"\", regex=False)\n",
    "\n",
    "# Make sure types are right\n",
    "amic = amic.dropna(subset=[\"Cover\"]).astype({\"Year\": int, \"Cover\": float})\n",
    "\n",
    "amic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc57b53e-a92f-4d92-a420-75dbf7ef39c2",
   "metadata": {},
   "source": [
    "## Problem 4* - Let's explore the ice data [difficult]\n",
    "\n",
    "A major part of data analysis is looking at code others have written and modifying it to do what you need. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf276f3e-4486-4192-b8c0-955e07122e31",
   "metadata": {},
   "source": [
    "Load the Pokemon data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f19028-80ea-4319-8980-c550bae0c4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon=pd.read_csv(\"../data/pokemon.csv\")\n",
    "pokemon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd556b3b-bdba-4b05-89bf-2c8ddc2fd9e0",
   "metadata": {},
   "source": [
    "- 1. Analyze the anatomy of this function I wrote to explore the pokemon data:\n",
    "The code below has many things you have seen before but also some new ones. That's ok. \n",
    "\n",
    "You may identify places where I oculd have done something differently or more efficient. \n",
    "That's ok! Everyone writes code to their best abilities and as long as it works others can read it then that's good.\n",
    "\n",
    "\n",
    "- 2. Identify its main components:\n",
    "\n",
    "Inputs / arguments\n",
    "\n",
    "Setting up figure + subplots\n",
    "\n",
    "Looping over y-variables\n",
    "\n",
    "Scatterplots and regression lines\n",
    "\n",
    "Adding regression stats as text\n",
    "\n",
    "Titles, labels\n",
    "\n",
    "saving output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b9b0af-3f61-4691-a034-ac75e8db8bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pokemon_plot(x_stat='Defense',stats_all=['HP','Attack','Total','Sp. Atk','Sp. Def','Speed']):\n",
    "    \n",
    "    \"\"\"This function will plot some stat vs all the other stat values, with a line, the equation to the line \n",
    "    and simple summary stats. The function can be mofidied to plot up to 6 subplots\"\"\"\n",
    "\n",
    "    #set up working space we will add subplots with the for loop\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.2)\n",
    "\n",
    "    #set figure size\n",
    "    fig.set_size_inches(15,8)\n",
    "\n",
    "    for count,y_stat in enumerate(stats_all):\n",
    "        #remember that for position we need three numbers, they need to be intergers\n",
    "        \n",
    "        ######these lines will change based on our inputs and edit our layout ####\n",
    "        if len(stats_all)<=3:\n",
    "            ax = fig.add_subplot(1, len(stats_all), int(count+1))\n",
    "        elif len(stats_all)==4:\n",
    "            ax = fig.add_subplot(2, 2, int(count+1))\n",
    "        else:\n",
    "            ax = fig.add_subplot(2, 3, int(count+1))\n",
    "            \n",
    "        ###############\n",
    "\n",
    "        #let's create a boolean command so only the first subplot has a legend for generation\n",
    "        if count>0:\n",
    "            #myplot - siple regression plot\n",
    "            ax=sns.scatterplot(x=x_stat, y=y_stat, data=pokemon,hue='Generation',legend=None)\n",
    "        else:\n",
    "            #myplot - siple regression plot\n",
    "            ax=sns.scatterplot(x=x_stat, y=y_stat, data=pokemon,hue='Generation')\n",
    "\n",
    "        ax.set_xlabel(x_stat,fontsize=18)\n",
    "        ax.set_ylabel(y_stat,fontsize=18)\n",
    "\n",
    "        #####get stats and add them here with a line ####\n",
    "\n",
    "        #regplot doesn't print any stats so let's use scipy to get some stats and add it to our plots\n",
    "        ##get stats for a label\n",
    "        #we use [[]] to select columns from dataframes\n",
    "        temp=pokemon[[x_stat,y_stat]].dropna()\n",
    "        #same as pokemon.loc[,[x_stat,y_stat]].dropna()\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(temp.iloc[:,0],temp.iloc[:,1])\n",
    "        #print (results)\n",
    "\n",
    "        ##this code makes the labels in the box\n",
    "        props=dict(boxstyle='round',facecolor='white',alpha=.4)\n",
    "        #here is a useful example of .format where you can chane the number format\n",
    "        textstr='m={:.3f}\\nb={:.3f}\\n$r^2$={:.2f}\\np={:.3}'.format(slope,intercept,r_value**2,p_value) #grabs the values from stats_out\n",
    "        # here the {} hold the formatting for each value that we will pass to format, the \\n means we want a new line\n",
    "        ax.text(.75,.05,textstr,transform=ax.transAxes,va='bottom',fontsize=11,bbox=props) #change the formatting of the box\n",
    "\n",
    "        ##### add a line plot\n",
    "\n",
    "        #this code here allows me to make a line manually\n",
    "        x1=np.array([temp[x_stat].min(),temp[x_stat].max()])\n",
    "        y1=slope*x1+intercept\n",
    "        #this will plot my line on top of the line from regplot\n",
    "        ax.plot(x1,y1)\n",
    "\n",
    "        ## add line equation as a title y=mx+b, m=slope, b=intercept\n",
    "        ax.set_title('y={:.3f}x+{:.2f}'.format(slope,intercept))\n",
    "\n",
    "    #add a figure title\n",
    "    plt.suptitle(f'Relationship: Stat vs {x_stat}',fontsize=18)\n",
    "\n",
    "    #use tight_layout to fix the layout issues we are gaving \n",
    "    plt.tight_layout()\n",
    "\n",
    "    #to save - \n",
    "    #the name will be in the fstring and will note the x_stats and how many other stats we called\n",
    "    plt.savefig(data_out_directory+f\"pokemon_scatter{x_stat}vsOthers{len(stats_all)}.pdf\")\n",
    "\n",
    "    #show my figure  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9ccdb8-5a3d-4720-9dd9-517e47c15be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## play with the inputs!!\n",
    "make_pokemon_plot(stats_all=['HP','Total','Attack',],x_stat='Speed')\n",
    "#make_pokemon_plot(stats_all=['HP','Total','Speed','Defense','Attack'],x_stat='Speed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a3da28-93f4-4604-b799-e70f2064b238",
   "metadata": {},
   "source": [
    "Based of my function above write one from the AMIC data. \n",
    "\n",
    "Task:\n",
    "\n",
    "Write a function plot_amic_regressions() with the following behavior:\n",
    "\n",
    "- Arguments: lakes: list of lake names (e.g., ['Superior','Erie']); years: range years (e.g., (2010,2020)); \n",
    "\n",
    "- What it does:\n",
    "\n",
    "    * Subset the AMIC data to the selected lakes and years.\n",
    "\n",
    "    * For each selected lake:\n",
    "\n",
    "    * Plot Year (x) vs Ice Cover % (y).\n",
    "\n",
    "    * Add a scatterplot and a linear regression line.\n",
    "\n",
    "    * Display regression stats (slope, intercept, $r^2$, p-value) in a text box.\n",
    "\n",
    "    * Add the equation of the line as subplot title.\n",
    "\n",
    "    * Arrange all lakes into subplots.\n",
    "\n",
    "    * Add a big figure title: \"Annual Max Ice Cover Trends\"\n",
    " \n",
    "    * Save your plot\n",
    "\n",
    "\n",
    "Play around with plotting different lakes and years. \n",
    "What do you notice about ice trends?\n",
    "Where you born on a high/low ice year?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc035e1-d914-4111-b419-bd2dc51c4e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code \n",
    "\n",
    "def plot_amic_regressions(selected_lakes=['Superior','Michigan','Huron'], \n",
    "                         year_range=(1973, 2019),\n",
    "                         data=amic):\n",
    "    \"\"\"\n",
    "    This function creates regression plots for selected Great Lakes ice coverage over time.\n",
    "    It shows trends, equations, and statistics similar to the Pokemon example.\n",
    "    Assumes at least 5 years of data will be included in the analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    - selected_lakes: list of lake names to include in analysis\n",
    "    - year_range: tuple of (start_year, end_year) to filter data (minimum 5 years)\n",
    "    - data: DataFrame containing ice coverage data (amic)\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter data by year range \n",
    "    \n",
    "    # Filter by selected lakes - teaching boolean indexing\n",
    "\n",
    "    # Set up figure working space - following Pokemon example structure\n",
    "\n",
    "    # Set figure size \n",
    "\n",
    "\n",
    "    # Loop through each selected lake \n",
    "\n",
    "        # Create subplot layout logic\n",
    "        # Get data for this specific lake\n",
    "        # Create scatter plot - basic visualization\n",
    "        # Set labels with proper font size \n",
    "\n",
    "\n",
    "        # Calculate regression statistics - following Pokemon example\n",
    "        # Remove any missing data points and ensure numeric data types\n",
    "\n",
    "        # Since we assume at least 5 years, proceed with regression\n",
    "        # Calculate linear regression \n",
    "\n",
    "        # Create text box with statistics - following Pokemon format\n",
    "\n",
    "        # Add text box to plot with stats \n",
    "\n",
    "        #make a line manually\n",
    "        # add line equation as a title\n",
    "\n",
    "    # Add overall title\n",
    "\n",
    "    # Improve layout \n",
    "\n",
    "    #save fig\n",
    "\n",
    "    #show my figure  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9703b77-031a-459a-9b52-641c66f6bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check output\n",
    "plot_amic_regressions(\n",
    "    selected_lakes=['All_Lakes','Superior', 'Erie', 'Michigan','Huron','Ontario'],\n",
    "    year_range=(1973, 2025))\n",
    "\n",
    "plot_amic_regressions(\n",
    "    selected_lakes=['Superior', 'Erie', 'Michigan'],\n",
    "    year_range=(1980, 2015))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949c720a-4f89-4e68-91b9-fb3a5d1a949a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e744d3d-3460-4347-a191-74d0d261ace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_amic_regressions(selected_lakes=['Superior','Michigan','Huron'], \n",
    "                         year_range=(1973, 2019),\n",
    "                         data=amic):\n",
    "    \"\"\"\n",
    "    This function creates regression plots for selected Great Lakes ice coverage over time.\n",
    "    It shows trends, equations, and statistics similar to the Pokemon example.\n",
    "    Assumes at least 5 years of data will be included in the analysis.\n",
    "    \n",
    "    Parameters:\n",
    "    - selected_lakes: list of lake names to include in analysis\n",
    "    - year_range: tuple of (start_year, end_year) to filter data (minimum 5 years)\n",
    "    - data: DataFrame containing ice coverage data (amic)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter data by year range \n",
    "    filtered_data = data.loc[(data['Year'] >= year_range[0]) & \n",
    "                        (data['Year'] <= year_range[1]),]\n",
    "    \n",
    "    # Filter by selected lakes - teaching boolean indexing\n",
    "    lake_data = filtered_data.loc[filtered_data['Lake'].isin(selected_lakes),]\n",
    "    \n",
    "    # Set up figure working space - following Pokemon example structure\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.3)\n",
    "    # Set figure size \n",
    "    fig.set_size_inches(16, 10)\n",
    "    \n",
    "    # Loop through each selected lake \n",
    "    for count, lake_name in enumerate(selected_lakes):\n",
    "        \n",
    "        # Create subplot layout logic \n",
    "        if len(selected_lakes) <= 3:\n",
    "            ax = fig.add_subplot(1, len(selected_lakes), count + 1)\n",
    "        elif len(selected_lakes) == 4:\n",
    "            ax = fig.add_subplot(2, 2, count + 1)\n",
    "        else:\n",
    "            ax = fig.add_subplot(2, 3, count + 1)\n",
    "        \n",
    "        # Get data for this specific lake \n",
    "        lake_subset = lake_data[lake_data['Lake'] == lake_name].copy()\n",
    "        \n",
    "        # Create scatter plot - basic visualization\n",
    "        ax.scatter(lake_subset['Year'], lake_subset['Cover'], \n",
    "                  color='steelblue', alpha=0.7, s=30)\n",
    "        \n",
    "        # Set labels with proper font size \n",
    "        ax.set_xlabel('Year', fontsize=14)\n",
    "        ax.set_ylabel('% Ice Coverage', fontsize=14)\n",
    "        ax.set_title(f'AMIC - Lake {lake_name}', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Calculate regression statistics - following Pokemon example\n",
    "        # Remove any missing data points and ensure numeric data types\n",
    "        clean_data = lake_subset[['Year', 'Cover']].dropna().copy()\n",
    "        \n",
    "        # Since we assume at least 5 years, proceed with regression\n",
    "        # Calculate linear regression \n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(clean_data['Year'], clean_data['Cover'])\n",
    "        \n",
    "        # Create text box with statistics - following Pokemon format\n",
    "        textbox_props = dict(boxstyle='round', facecolor='lightblue', alpha=0.8)\n",
    "        stats_text = f'Slope: {slope:.3f}\\nIntercept: {intercept:.1f}\\nR²: {r_value**2:.3f}\\np-value: {p_value:.3f}'\n",
    "        \n",
    "        # Add text box to plot with stats\n",
    "        ax.text(0.05, 0.45, stats_text, transform=ax.transAxes, \n",
    "               verticalalignment='top', fontsize=10, bbox=textbox_props)\n",
    "\n",
    "\n",
    "        #make a line manually\n",
    "        x1=np.array([clean_data['Year'].min(), clean_data['Year'].max()])\n",
    "        y1=slope * x1 + intercept\n",
    "        #this will plot my line on top of the line from regplot\n",
    "        ax.plot(x1,y1, color=\"red\")\n",
    "\n",
    "        #add line equation as a title\n",
    "        m=slope\n",
    "        b=intercept\n",
    "        ax.set_title('y={:.3f}x+{:.2f}'.format(m,b))\n",
    "        \n",
    "    \n",
    "    # Add overall title \n",
    "    plt.suptitle(\"Annual Max Ice Cover Trends\",fontsize=18, y=0.98)\n",
    "    \n",
    "    # Improve layout and show\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #save fig\n",
    "    plt.savefig(\"../output/my_ice_trends.png\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Check output\n",
    "#plot_amic_regressions(\n",
    "#    selected_lakes=['All_Lakes','Superior', 'Erie', 'Michigan','Huron','Ontario'],\n",
    "#    year_range=(1973, 2025))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282efd24-31a0-4103-8529-17aa6b43317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_amic_regressions(\n",
    "    selected_lakes=['All_Lakes','Superior', 'Erie', 'Michigan','Huron','Ontario'],\n",
    "    year_range=(1973, 2025))\n",
    "\n",
    "plot_amic_regressions(\n",
    "    selected_lakes=['Superior', 'Erie', 'Michigan'],\n",
    "    year_range=(1980, 2015))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68621dcb-6792-41af-b3af-79b5697bca3b",
   "metadata": {},
   "source": [
    "## Problem 5 - GeoPandas in the Great Lakes area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7150f5-7085-48f8-8a98-86a0c1923064",
   "metadata": {},
   "source": [
    "### A) Plot lakes in the Great Lakes region above a size threshold\n",
    "\n",
    "Prompt: From lakes, plot all polygons that:\n",
    "\n",
    "intersect the Great Lakes bounding box (lon [-170, 5], lat [-50, 83]), and\n",
    "\n",
    "have area ≥ 1,000 km².\n",
    "    \n",
    "Show all lakes in red context, highlight the selected >1,000km2 lakes in a darker color, hide axes, and add a title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f08181-34c1-4a78-9a1e-d9c8bd3afd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import box\n",
    "\n",
    "\n",
    "# Load lakes\n",
    "lakes = gpd.read_file(\"../data/ne_10m_lake.zip\")\n",
    "\n",
    "# Great Lakes bounding box (rough)\n",
    "gl_bbox = box(-170, 5, -50, 83) \n",
    "\n",
    "\n",
    "### your code\n",
    "\n",
    "# Compute area in km² using an equal-area CRS (Great Lakes Albers)\n",
    "\n",
    "# Selection: intersects bbox AND area ≥ 1,000 km²\n",
    "\n",
    "# Plot: context (red) + selected (darker)\n",
    "\n",
    "### my help :)\n",
    "\n",
    "# Zoom, tidy, title\n",
    "ax.set_xlim(-93, -74)\n",
    "ax.set_ylim(41, 50)\n",
    "ax.set_axis_off()\n",
    "ax.set_title(\"Lakes ≥ 1,000 km² in the Great Lakes Region\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71104f8-cef6-4d64-80d9-d0eaf23127d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659d1040-9750-4b56-81e3-2a520f7d1815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import box\n",
    "\n",
    "# Load lakes\n",
    "lakes = gpd.read_file(\"../data/ne_10m_lake.zip\")\n",
    "\n",
    "# Normalize to WGS84 for spatial filtering/plotting\n",
    "lks = lakes.to_crs(4326)\n",
    "\n",
    "# Great Lakes bounding box (rough)\n",
    "gl_bbox = box(-170, 5, -50, 83) \n",
    "\n",
    "# Compute area in km² using an equal-area CRS (Great Lakes Albers)\n",
    "lks_eq = lks.to_crs(3175)  # EPSG:3175\n",
    "lks = lks.copy()\n",
    "lks[\"area_km2\"] = lks_eq.geometry.area / 1e6\n",
    "\n",
    "# Selection: intersects bbox AND area ≥ 1,000 km²\n",
    "sel = lks[lks.intersects(gl_bbox) & (lks[\"area_km2\"] >= 1000)]\n",
    "\n",
    "# Plot: context (red) + selected (darker)\n",
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "lks.plot(ax=ax, color=\"red\", edgecolor=\"white\", linewidth=0.5)\n",
    "sel.plot(ax=ax, color=\"lightblue\", edgecolor=\"black\", linewidth=0.7)\n",
    "\n",
    "# Zoom, tidy, title\n",
    "ax.set_xlim(-93, -74)\n",
    "ax.set_ylim(41, 50)\n",
    "ax.set_axis_off()\n",
    "ax.set_title(\"Lakes ≥ 1,000 km² in the Great Lakes Region\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94e222b-ed2b-4e0b-8da2-25abc9062b5f",
   "metadata": {},
   "source": [
    "### B) color your favorite great lake to your favorite color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036708f2-0d89-47f1-b813-dd83a451d643",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your work \n",
    "\n",
    "## use your code from above "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166cf1f9-f10b-4cd7-b594-8eb4172e452b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562db7bf-061a-4c65-bd6b-aa2b4e380a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "is_sup = lks[\"name\"].str.contains(\"Superior\", case=False, na=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "\n",
    "# all other lakes in black\n",
    "lks.loc[~is_sup].plot(ax=ax, color=\"black\", edgecolor=\"black\", linewidth=0.4)\n",
    "\n",
    "# lake superior in pink\n",
    "lks.loc[is_sup].plot(ax=ax, color=\"pink\", edgecolor=\"black\", linewidth=0.6)\n",
    "\n",
    "# optional zoom if you have gl_bbox\n",
    "minx, miny, maxx, maxy = gl_bbox.bounds\n",
    "\n",
    "# Zoom, tidy, title\n",
    "ax.set_xlim(-93, -74)\n",
    "ax.set_ylim(41, 50)\n",
    "ax.set_axis_off()\n",
    "ax.set_title(\"BlackPink in your area! :)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py101)",
   "language": "python",
   "name": "py101"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
